#app/ai/goal_parser_chain.py
# === goal_parser_chain.py ===
# This file contains the LangChain chain that parses natural language goal descriptions
# into structured plans following our AI-driven schema (goal ‚Üí cycles ‚Üí occurrences ‚Üí tasks)


from langchain_openai import ChatOpenAI                     # ‚úÖ Interface to OpenAI chat models
from langchain.prompts import ChatPromptTemplate            # ‚úÖ Helps define reusable prompt structure
from langchain.output_parsers import PydanticOutputParser, OutputFixingParser   # ‚úÖ Enforces Pydantic schema on LLM output
from app.ai.schemas import GeneratedPlan                    # ‚úÖ Import your structured schema
import os                                                   # ‚úÖ For environment variable access     
from pydantic import SecretStr
from decouple import config
from langchain.schema.runnable import RunnableMap
from datetime import date
from datetime import datetime, timezone  # For handling timestamps in feedback


#Create a reusable LangChain pipeline that:
# Accepts a natural language input (user‚Äôs goal description)
# Sends it to the LLM
# Returns a structured GeneratedPlan object parsed into your new schema


# ‚úÖ Create an output parser that forces LLM to return `GeneratedPlan` schema
base_parser = PydanticOutputParser(pydantic_object=GeneratedPlan)

# ‚úÖ Use the base parser directly instead of OutputFixingParser to avoid the chain issue
parser = base_parser

# ‚úÖ If you want auto-fixing later, use this configuration:
# openai_api_key_str = str(config("OPENAI_API_KEY"))
# llm_for_fixing = ChatOpenAI(
#     model=os.getenv("OPENAI_MODEL", "gpt-4"),
#     temperature=0.2,
#     api_key=SecretStr(openai_api_key_str)
# )
# 
# # Create a simple fixing chain
# from langchain.prompts import ChatPromptTemplate
# fixing_prompt = ChatPromptTemplate.from_template(
#     "Fix the following JSON to be valid:\n{completion}\n\nFixed JSON:"
# )
# retry_chain = fixing_prompt | llm_for_fixing
# 
# parser = OutputFixingParser(
#     parser=base_parser,
#     retry_chain=retry_chain
# )

# ‚úÖ Define the prompt template with placeholders for dynamic content, i.e, for the LLM (system + user)
# ‚úÖ Create the system prompt that guides the LLM

today = date.today().isoformat()

prompt_template = ChatPromptTemplate.from_messages([
    ("system", 
     f"""
     You are a smart AI personal planner. Today‚Äôs date is {today}. 
     Use this as the base for all scheduling decisions.
     """
    ),
    ("user",
    """
    A user will describe a personal goal in natural language. 
    Given the user's natural language description of a goal, generate a structured goal planning breakdown.

    Your response MUST:
    - Follow the exact JSON structure defined by this format:
    {format_instructions}

    The plan must include:
    ‚úÖ Top-level goal metadata:
    - title
    - description
    - goal_type ("habit" or "project")
    - start_date (must be today or later)
    - progress (0‚Äì100)

    üîÅ If goal_type is **"habit"**, you MUST also include:
    - goal_frequency_per_cycle (e.g., 2)
    - goal_recurrence_count (e.g., 12)
    - recurrence_cycle (e.g., "monthly")
    - default_estimated_time_per_cycle (e.g., 120)
    - habit_cycles ‚Üí each with:
        - cycle_label
        - start_date / end_date
        - occurrences ‚Üí each with:
            - occurrence_order
            - estimated_effort
            - 2‚Äì4 tasks with:
                - title
                - due_date
                - estimated_time

    üì¶ If goal_type is **"project"**, you MUST include:
    - end_date (at least 2 weeks after start_date)
    - tasks (directly under goal)

    ‚ö†Ô∏è Temporal Constraints:
    - All dates must be in the future
    - Habit end_date is optional if ongoing
    - Project end_date is required and ‚â• 2 weeks after start_date

    Do NOT include motivational or extra explanation text. Only return valid structured data.

    User goal: {goal_description}

    Today's date: {today_date}
    """
    )
])

# app/ai/refinement_prompt.py (or you can inline it in goal_parser_chain.py if preferred)

refinement_prompt_template = ChatPromptTemplate.from_messages([
    ("system", 
     f"""
     You are a smart AI personal planner who revises structured goal plans based on user feedback.
     Today‚Äôs date is {today}. Make sure all output respects today‚Äôs date.
     """
    ),
    ("user",
     """
     A user previously generated a structured goal plan, but they provided feedback asking for improvements.

     Your task:
     - Review the original goal description
     - Consider the user's feedback
     - Improve the previously generated plan accordingly

     Strictly follow these output rules:
     - All dates must be in the future (not before today)
     - For project goals:
         - Start date must be today or later
         - End date must be at least 2 weeks after start date
     - For habit goals:
         - End date is optional (may be recurring forever)
     - Inside each cycle or plan:
         - Add 2‚Äì4 detailed tasks per occurrence
         - Include one main task and one supporting/preparation task
         - Provide realistic due dates and estimated times

     You MUST follow this output format:
     {format_instructions}

     Original goal description:
     {goal_description}

     User feedback:
     {prior_feedback}

     Previous structured plan to refine:
     {previous_plan}

     Return only a valid structured plan. Do not include extra explanation or chat text.
     """
    )
])


# ‚úÖ Bind the format instructions
prompt = prompt_template.partial(format_instructions=parser.get_format_instructions())

refinement_prompt_template = refinement_prompt_template.partial(
    format_instructions=parser.get_format_instructions()
)


# ‚úÖ Connect the LLM (OpenAI model ‚Äî use GPT-4 or GPT-3.5)

openai_api_key = config("OPENAI_API_KEY")  # Raises error if missing

llm_kwargs = {
    "model": os.getenv("OPENAI_MODEL", "gpt-4"),
    "temperature": 0.2,
}
if isinstance(openai_api_key, str) and openai_api_key:
    llm_kwargs["api_key"] = SecretStr(openai_api_key)

llm = ChatOpenAI(**llm_kwargs)

# ‚úÖ Create the goal parser chain that combines the prompt, LLM, and output parser
# ‚úÖ Combine everything into a full chain: prompt ‚Üí LLM ‚Üí parser

goal_parser_chain = RunnableMap({
    "plan" : prompt | llm | parser
})


# ‚úÖ Create the refinement chain that uses the refinement prompt, LLM, and output parser
refine_plan_chain = RunnableMap({
    "plan" : refinement_prompt_template | llm | parser
})


