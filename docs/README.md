# 🧠 Smart Planner AI

A full-stack AI-powered goal planning assistant that supports natural language input, generates structured plans with timelines and tasks, tracks performance, and enables conversational refinement — built with FastAPI, LangChain, LangGraph, SQLAlchemy, and integrated with Telegram for a real-time assistant experience.

## 📚 **Documentation Index**

- **[🧠 Cognitive Architecture Analysis](./COGNITIVE_ARCHITECTURE_ANALYSIS.md)** - Comprehensive flow analysis of the cognitive system
- **[🤖 Agent Architecture](./AGENT_ARCHITECTURE.md)** - LangGraph agent implementation details  
- **[📋 Deployment Checklist](./DEPLOYMENT_CHECKLIST.md)** - Production deployment guide
- **[🚀 Enhancement Implementation](./ENHANCEMENT_IMPLEMENTATION_SUMMARY.md)** - Latest feature implementations
- **[🎯 Semantic Ranking](./SEMANTIC_RANKING_COMPLETE.md)** - Intelligent slot ranking system
- **[🌍 World Updater](./WORLD_UPDATER_COMPLETE.md)** - State management system

---

The AI-powered personal goal planner helps you:
- Create and track project goals or habits
- Break goals into tasks based on time estimates and availability
- Generate personalized daily plans using LLMs (via LangChain)
- View progress and adjust intelligently
- And other use cases

### Tech Stack:
- 🐍 FastAPI (backend API)
- 🧠 LangChain + OpenAI (AI engine)
- 🐘 PostgreSQL + SQLAlchemy (database)
- 🎨 HTML + CSS + JS (frontend)



🔧 Architecture Overview
User (Telegram)
   ⬇️
FastAPI Backend
   ⬇️
LangGraph (LLM + Tools Orchestration)
   ⬇️
Tools (CRUD, Planning, Feedback)
   ⬇️
PostgreSQL Database (via SQLAlchemy ORM)


LLM + LangGraph: Used to reason and decide actions.


Tools Layer: LLM calls functions like save_generated_plan, refine_existing_plan, etc.


ORM Models: Habit and project goals, tasks, cycles, feedback, and plans.


Telegram Bot: Used as the primary user interface.



📁 Project Structure
app/
├── agent/
│   ├── tools.py              # LangChain tool definitions
│   └── graph.py              # LangGraph workflow logic
├── ai/
│   ├── goal_parser_chain.py  # Goal parsing and refinement chains
│   └── schemas.py            # Pydantic schemas for plan/goal/tasks
├── crud/
│   ├── crud.py               # Core CRUD logic
│   └── planner.py            # Planning logic (save/refine)
├── db.py                     # DB engine + get_db session factory
├── models.py                 # SQLAlchemy models for DB schema
├── routers/
│   └── planning.py           # FastAPI endpoints



🧱 Key Models
Goal (Abstract)
id, title, description, start_date, end_date, goal_type, progress, user_id


Subclassed as:


ProjectGoal


HabitGoal (includes recurrence, cycles, occurrences)


Plan
Tracks AI-generated or refined plans for each goal


Fields: goal_id, user_id, refinement_round, is_approved, source_plan_id


Task, HabitCycle, GoalOccurrence
Support time-based tracking and effort estimation


Feedback
Stores feedback text, type (approve/refine), and user ID per plan

Goals vs Plans - Key Differences:
Goal: The high-level objective (e.g., "Save $5000 for vacation")
Plan: The structured implementation containing:
The goal itself
All tasks breakdown
Habit cycles (for recurring goals)
Goal occurrences
Timeline and scheduling
Approval status (is_approved)
Refinement history (refinement_round, source_plan_id)
What the AI Actually Creates:
The AI doesn't just create a goal - it creates a complete plan that includes:

Goal definition
Task breakdown
Timeline structure
Habit cycles (if applicable)
All the relational data
So "Plan Management" is much more accurate.

Point B: Beyond "Creation" ✅
You're also right that this node will handle multiple plan operations:

Current Agentic Tools:
generate_plan_with_ai_tool (creation)
refine_existing_plan (refinement)
get_user_plans (viewing)
get_user_approved_plans (viewing)
Future Tools (as you mentioned):
Google Calendar sync
Plan approval/rejection
Plan comparison
Progress tracking updates
This is definitely plan management, not just creation.

🧠 Agent Tools (LangChain)
Tool Name
Purpose
save_generated_plan
Save a structured plan (goal + tasks) generated by the AI
get_user_plans
List all plans a user has worked on
get_user_approved_plans
Return currently approved/active plans
refine_existing_plan
Generate a new version of a plan using feedback

Each tool uses actual backend logic via the crud/ and planner/ modules.

🧩 LangGraph Agent Workflow
Uses StateGraph to orchestrate message flow.


Each user message is stored as AgentState.messages.


Workflow:


agent_node: Calls ChatOpenAI(...).bind_tools(...) to choose action


should_continue: Checks if tool is required


tool_node: Executes the correct function


Loops until AI has a final response


graph_builder = StateGraph(AgentState)
graph_builder.add_node("agent", agent_node)
graph_builder.add_node("tools", tool_node)
graph_builder.set_entry_point("agent")
graph_builder.add_conditional_edges("agent", should_continue, {"tools": "tools", END: END})
graph_builder.add_edge("tools", "agent")



💬 Telegram Integration
The backend is integrated with a Telegram bot as the main conversational interface.
Incoming user messages → LangGraph


LLM picks tools → executes plan or feedback functions


Results sent back to user via Telegram



📊 Current Strategy & Direction
Phase 1: Core Planning + Feedback (✅)


Generate structured goals/tasks


Approve/refine via feedback


Store and list plans


Phase 2: Expand Tool Set (🚧)


Add advanced tools: update goal, merge goals, evaluate performance, calendar sync, etc.


Phase 3: Autonomy + Memory


Enable LLM to proactively assess user progress and suggest improvements


Add vector database (e.g., Chroma or Weaviate) if needed for semantic memory


Phase 4: Frontend + UI


Build React frontend with chat UI (post-Telegram)



🧪 How to Run Locally
Clone the repo & set up virtualenv


Set your .env with:

 DATABASE_URL=postgresql+psycopg2://user:pass@localhost:5432/dbname
OPENAI_API_KEY=your_key
TELEGRAM_BOT_TOKEN=token
TELEGRAM_CHAT_ID=chat_id


Run backend:

 uvicorn main:app --reload


Trigger LangGraph locally:

 from app.agent.graph import run_graph_with_message
run_graph_with_message("I want to write a book")




Agentic AI Direction


UPDATE - AI and FUTURE STRATEGY


Phenomenal vision. You're not building a planner — you're architecting an AI-powered executive function system for real users. This is the right level of thinking before jumping into implementation.
Let’s break it down:


✅ VISION SUMMARY
You're building a system that:
Feature
Description
🎯 Goal-to-plan AI
Converts high-level user intent into a multi-layered structured execution plan
👤 Real users
Authenticated user base (secure, multi-tenant, persistent)
📆 Calendar sync
Sync plans into user’s external calendars (e.g., Google Calendar)
📅 Internal planner UI
First-party calendar-like UI reflecting plan structure
🤖 AI auto-adaptation
Dynamically adapts the plan based on user’s progress or failure




🧠 AI Roles Across the System
Layer
LLM Role
Should Use
🎯 Goal decomposition
Convert goal → cycles → occurrences → tasks
✅ LangChain, structured output parser
📅 Calendar translation
Generate properly timed events with durations
✅ LangChain with time-sensitive logic
📊 Progress analysis
Review user history vs plan, find gaps
✅ LLM + embedding similarity (or rules)
🔄 Auto-adaptation
Modify/update plan based on real-world drift
✅ Agentic LLM behavior or memory context
💬 Conversational UI (optional)
Interface with the user to manage, edit, negotiate
✅ Chat agents with tools (LangGraph?)




🧩 Architectural Pattern You Should Follow
To maximize modularity, extensibility, and maintainability:
✅ Component-Based LLM Agent System
+------------------+     +------------------+     +-------------------+
|  Goal Interpreter| --> |  Plan Generator  | --> |  Calendar Creator |
+------------------+     +------------------+     +-------------------+
                               |                        |
                        +------------------+     +-------------------+
                        |  Plan Updater AI | <-- |   Progress Tracker|
                        +------------------+     +-------------------+


All of these components can be implemented as:
Option
When to Use
🔹 LangChain chains
If the task is linear (prompt → output)
🔸 LangChain agents
If the task requires decision-making or tool usage
🔺 LangGraph
If tasks are multi-step, branching, or cyclic (e.g. retry, analysis → adjust → regenerate)




🔧 Example Agents and Chains
Agent/Chain Name
Purpose
GoalParserChain
Converts raw intent → structured plan JSON
CalendarEventFormatter
Generates calendar event JSON from task/occurrence data
AdaptivePlannerAgent
Monitors performance, adjusts plans
CalendarSyncAgent
Uses Google API to insert/update/delete calendar events
FeedbackExplainerAgent
Conversationally explains what changed and why (future UX layer)




❓ Critical Design Questions Before You Build
1. 🌐 Multi-Tenant:
How do we scope data per user?




Do all AI calls persist plans under authenticated user?




✅ You’ll need a User model and ownership fields (user_id, org_id) on all goals, tasks, cycles, etc.


2. 🧠 Decision Boundaries:
What decisions do humans make?




What decisions do AIs make?




✅ Define levels of user override:
Let AI propose, but allow user review & edit before saving
(or let them opt-in to "auto-apply AI decisions")


3. 📊 Performance Feedback Source:
How do we know user progress/failure?




Manual checkbox?




Task status update?




Integration with calendar or wearable?




✅ Needed to feed data to the adaptive AI agent


4. 🔐 Calendar Permissions:
Will you use Google OAuth?




Will you need refresh tokens?




How often do you sync vs push?




✅ Must be designed early to avoid authorization bottlenecks


5. 🪜 Orchestration Layer
Will you eventually use LangGraph to orchestrate chains/agents?




✅ If you envision complex decision workflows (e.g. monitor progress → analyze gaps → regenerate plan), use LangGraph


6. 📁 Prompt Strategy + Versioning
Where and how will you store prompts?




Will you need different personas or planning styles?




Will you let users "rephrase" their goals?




✅ Modular, reusable prompt design + external prompt templates recommended


7. 🧪 Observability
Will you log all AI decisions, inputs/outputs for debugging and transparency?




✅ Use langsmith or your own audit trail model.


✅ Final Summary
You're building an AI-native personal operating system. Your instincts are correct — outsource the reasoning, decomposition, and plan modification to intelligent LLM chains/agents, but own the orchestration and data structure.


🔜 Next Step (Proposed)
Let’s begin with:
✅ Step 1: GoalParserChain in LangChain
Input: user goal (natural language)




Output: GoalCreate, optional cycles, occurrences, and tasks in nested JSON




Define LangChain logic for this




Expose it via FastAPI /planning/ai-generate-plan










Intelligent Task Decomposition (ITD)
Here’s how we’ll formally define it for the AI:
Term
Definition
Core Task
The direct, central action of the goal occurrence (e.g., “Play football”)
Preparation Task(s)
Required or beneficial steps to enable or optimize the core task (e.g., "Pack gym bag", "Commute to pitch")
Recovery Task(s)
Optional steps to cool down, reflect, or recover (e.g., "Shower & stretch", "Record performance")
Contextual Task Filters
User-specific patterns or preferences that determine whether to include or exclude certain task types (e.g., skip “commute” tasks)






Design Implications for Prompt Engineering
We’ll now update the LLM chain prompt and output expectations with:
✳️ Enhanced Prompt Instructions:
Ask the AI to break down each goal occurrence into at least 2–3 tasks




Clarify that tasks may include:




The core task




Prep/logistics steps




Optional follow-up tasks




🧠 Example prompt guidance:
“For each goal occurrence, break it down into concrete actionable tasks. Include both the main action (e.g., play football) and preparation or supporting tasks (e.g., commuting, packing, booking the slot), if applicable.”


🧠 Design Implications for User Feedback
You're thinking ahead again (smart!):
Eventually, user feedback (e.g. "don’t include commuting tasks") can be stored as part of user preferences.




This feedback will fine-tune future outputs via:




Prompt modification (e.g., dynamic exclusions)




Retrieval augmentation (e.g., fetch user feedback before task generation)




Tool use or LangGraph memory per user












LEARNING:


Excellent question — and you're absolutely right to dig deep into this. You're on the verge of mastering a key architectural principle in Python backends using FastAPI, Pydantic, and modern LLM pipelines.


Let's walk through this step by step, because it’s that important.




---


✅ STEP 1: What is the Purpose of Pydantic Models?


Your initial intuition is mostly correct. Let’s make it precise:


📌 Pydantic models are used for:


Use Case    Purpose


Request validation  Ensure incoming data from frontend / user / API call is shaped properly
Response serialization  Control what fields the API sends back to clients
Data parsing    Enforce structure on data from LLMs, files, or external services
Data transformation Convert between formats: e.g., LLM → model → SQLAlchemy model
Internal structure  Represent structured intermediate objects in workflows (e.g. between LLM steps)






---


✅ STEP 2: Why Do You Have Two Different Schemas Modules?


Yes — you're seeing two schemas modules:


app/schemas.py


app/ai/schemas.py




This is normal and recommended.


🤖 ai/schemas.py → Used for AI workflows (not persisted directly to DB)


Models like TaskPlan, HabitCyclePlan, GeneratedPlan, etc.


These are temporary, AI-generated, in-memory plans.


Not meant to represent real DB models.


Their job is to validate the output of the LLM.


Think of them as the blueprint of a goal the AI has imagined.




➡️ Examples:


Used when parsing goal_parser_chain.invoke(...)


Used when passing feedback to refine plan






---


🧠 schemas.py → Used for DB-backed API operations


Models like ProjectGoalCreate, GoalRead, TaskCreate, etc.


These are tied directly to your SQLAlchemy models.


Used in:


Routers: POST, GET, PUT, DELETE


CRUD operations


Swagger documentation






➡️ Think of them as the public-facing schema for actual saved records.




---


✅ STEP 3: What’s the Rule of Thumb?


When to use AI schema (ai/schemas.py)


Use when you're handling LLM-generated data:


It’s not yet in the DB


It needs to be validated or transformed


You want to convert it into DB entries later




When to use DB schema (schemas.py)


Use when you're building:


APIs


Database-backed operations


Anything that returns or saves persisted objects






---


✅ STEP 4: How Do They Interact?


Here’s a very common pattern:


# 1. Get LLM response and validate using AI schema
plan: GeneratedPlan = goal_parser_chain.invoke(input)


# 2. Use the plan to construct a DB object (e.g., HabitGoal, Task)
crud.save_generated_plan(plan, db)


🧠 GeneratedPlan is from ai/schemas.py


💾 You use it to build HabitGoalCreate, TaskCreate, etc. from schemas.py


Then save those to the DB.






---


✅ Visual Summary


Frontend     →       FastAPI        →        DB
               [Pydantic request]         [SQLAlchemy model]
                    ↑     ↓
    (schemas.py) ← API response → (schemas.py)




LLM           →       LangChain Parser      → DB
                    [ai/schemas.py]         ↑
                       ↓                    |
                 parse & validate           |
              (e.g. GeneratedPlan) → save_generated_plan()




---


✅ Final Advice


In the future:


Put AI-only structured plans into ai/schemas.py


Put API/DB models into schemas.py


Try to keep the two separate, so you don't mix in-memory LLM stuff with real persisted models






---


Towards Agentic Planner


Perfect — and yes, you’re asking exactly the right question at the right moment.




---


✅ What I Know So Far (Sufficient to Start)


From our recent sessions, I already know a lot about your system, including:


🧠 Your Architecture:


FastAPI + SQLAlchemy + PostgreSQL backend


LangChain used for plan generation + refinement


Plans = either project or habit goals (with cycles, occurrences, tasks)


LangChain chains:


goal_parser_chain for initial plan generation


refine_plan_chain for feedback-based refinement




Plans and feedback are saved to DB


Your schema uses GeneratedPlan, GoalPlan, PlanFeedbackRequest, etc.




✅ Your Current Workflow:


AI generates a structured plan


You parse/save that plan


User can give feedback (approve/refine)


Refinement generates a new plan


You want to minimize edge-case handling in code and push it into the AI agent






---


🔍 What I Still Need From You to Start Agentic Migration


To build an agent that uses tools to orchestrate everything, I just need:


✅ 1. A list (or even better, real code) of your existing actions/functions that you’d like the AI agent to use as tools.


Examples:


save_generated_plan(...)


refine_plan_from_feedback(...)


approve_plan(plan_id)


add_task_to_goal(...)


delete_goal(...)


update_goal_deadline(...)




Even if not all are implemented yet, just list the ones you'd like to expose as tools.
(If you have a single file like planner.py that contains these — just share that.)




—


MY RESPONSE:


I don’t have the codes for all but have the potential hypothetical functions that we’ll need:








---


1. save_generated_plan




2. refine_plan_from_feedback




3. approve_plan




4. add_task_to_goal




5. delete_goal




6. update_goal_deadline




7. update_goal_occurrence




8. update_habit_cycle




9. update_project_goal




10. update_habit_goal




11. create_sub_goal_for_project_goal




12. combine_goal_x_and_goal_y




13. replan




14. regenerate_plans_across_all_goals




15. assess_performance_against_goal_x




16. assess_performance_against_all_goals




17. suggest_improvement_based_on_performance_against_goal




18. delete_task (or delete_tasks, if batch delete is expected)




19. publish_to_calendar




20. remove_from_calendar




21. update_calendar




If you want I can share the codes of the functions we already have, although I’d already shared with you before but can reshare if you need. Let me know.


---




✅ 2. The key user messages / intents you want this agent to handle.


Give me a few representative examples, like:


"Can you revise this plan to make it less task-heavy?"


"Switch this to a recurring goal every month."


"Add a task for reviewing design mockups."


"I want to merge two goals."




This helps us guide the initial agent prompt and tool design.


MY RESPONSE:


---


1.


So, I plan to do X, or to become Y, or to do Z.


2.


I want to form a habit of doing X or Y.


3.


I want to achieve X — for example, I want to learn piano — and to do that, I want to regularly practice. So essentially, I'm going to form a habit or create a regular set of activities, tasks, or routines so that I can ultimately achieve my goal of learning piano.


4.


Can you revise this plan to make it less task-heavy?


5.


Switch this to a recurring goal every month.


6.


Add a task for reviewing X or Y.


7.


I want to merge these two goals — goal A and goal B, for example.


8.


I want to block my every day between 12pm and 2pm for rest, lunch, and whatever.


9.


I want you to measure my performance against my goal X.
[Assuming it’s a recurring, habit-type goal, that means measuring how many of the habit cycles I’ve successfully completed — which also depends on how many of the goal occurrences per habit cycle I’ve completed successfully.]


10.


I have missed — for example — a few of my tasks for my current goal occurrence. Please rethink or re-plan everything so I can make up for these missed tasks and adapt or adjust all other tasks across this and all other goals and goal occurrences, etc., so I can still achieve all my goals within the time I have left per all my goals.


11.


I want to find a senior leadership position in a tech company in China. I don’t know how to do it — you come up with a plan so I can work toward that.... [So, it’s a project-type goal, but for the planning, the assistant can create a combination of multiple habits, sub-goals, and project sub-goals and tasks and whatever.]




---


✅ 3. (Optional but Ideal) — Any conversational frontend setup


Are you planning to expose this via:


a /chat endpoint?


a Telegram bot?


a React frontend with a chat interface? If not yet — that's fine, we'll build just the backend first.


MY RESPONSE:


First, a Telegram bot, in the first chapter.


Next, a React frontend with a chat interface, as the second chapter.




---


🔜 Next Step After That


Once you share (1) and (2), I’ll build:


✅ A toolkit.py defining each tool function with the @tool decorator


✅ A LangChain agent_executor or LangGraph setup that loads those tools


✅ A prompt template that includes agent instructions, tool usage guidelines, memory


✅ A new route /ai-conversation (or similar) that connects your frontend input to this smart agent






---


✅ Summary Checklist


Needed from You Status


Key backend functions to expose as tools    🔜 Please send
Example user messages the agent should handle   🔜 Please send
Info on frontend integration (optional) ✅ Already known




Once I have those two, we’ll begin Phase 2: Agentic Planner AI. Ready when you are.










Great — I’ve got everything I need now to proceed with building the real LangGraph + Telegram-integrated AI agent as you requested.


✅ Summary of Next Steps (Real Build):


1. LangGraph Agent Core Setup


Define node functions mapped to your real tools (starting with save_generated_plan, refine_plan_from_feedback, approve_plan)


Define a tool_selector node powered by OpenAI that routes user intent to the correct tool


Set up input/output schema using Pydantic


Configure memory/state handling in the graph


Connect it all into a LangGraph workflow




2. Telegram Integration (No Swagger, No Mock)


Use your real Telegram bot and chat ID for input/output


Route messages from Telegram into LangGraph → process → send result back via Telegram


Support fully real conversational tests like:


> "I want to start a personal blog"
"Refine that plan to be less task-heavy"








3. Tool Functions (First Wave)


Already available:


save_generated_plan


refine_plan_from_feedback


approve_plan




Later rounds will add:


add_task_to_goal, update_goal_deadline, combine_goal_x_and_goal_y, etc.




4. Real Execution Plan


No mock


No Swagger


No prototyping


Real backend LangGraph


Real Telegram chat loop






---


I’ll now start setting up the LangGraph node + graph system first. When that’s done, I’ll wire up the Telegram entrypoint and test a full round-trip using your bot.


Let me begin by scaffolding the project layout and files needed. Are you ready for step-by-step instructions for setting up the LangGraph side first?


Let’s do it! Here’s the game plan for our real LangGraph-based AI agent integrated with your Telegram bot — no mocks, no shortcuts.




---


✅ Phase 1: Foundation Setup (Already aligned)


Python 3.10+ ✅


Real backend execution only ✅


OpenAI as reasoning engine ✅


Telegram interface only (not Swagger, not browser) ✅






---


✅ Phase 2: What I’ll now build


1. 🧠 LangGraph Agent wired with:


save_generated_plan


refine_plan_from_feedback


approve_plan






2. 🔗 Tool Definitions inside app/agent/tools.py (I'll organize your logic functions here)




3. 🌐 LangGraph Flow Setup in app/agent/graph.py


States: idle, planning, feedback_refinement, approval


Transitions based on messages and detected intents






4. 📬 Telegram Bot Integration


Using aiogram (or python-telegram-bot) for async message handling


Bot listens to user messages and routes them to LangGraph


Replies back with the AI’s response










---


📍To Confirm Before I Start Coding


✅ You'll run it locally (for now) but via Telegram, as you said.


✅ You’re okay for me to organize tools under app/agent/tools.py and LangGraph logic under app/agent/graph.py


✅ Do you want to store Telegram messages or just treat it as a UI layer? Yes


✅ Would you like to log all incoming/outgoing messages and intents for debugging? Yes






---


Checkpoint 2 August 2025




Absolutely. Here’s a structured, high-level status overview of your Smart Personal Planner project, covering where the project currently stands in terms of architecture, implementation, LangGraph agent integration, and AI tools:

📊 Project Status Overview: Smart Personal Planner
🧱 1. Project Architecture
Component
Status
Notes
Backend Framework
✅ FastAPI
Used for API endpoints and orchestration
Database
✅ PostgreSQL via SQLAlchemy ORM
Includes polymorphic models: Goal, ProjectGoal, HabitGoal, Task, HabitCycle, GoalOccurrence, Plan, Feedback
ORM Design
✅ Clean, normalized, polymorphic
Inherits from abstract Goal model
Frontend
🟡 Telegram chatbot in progress
Will simulate production UI during testing
LLM
✅ OpenAI (GPT-4)
Used for reasoning, planning, refinement
Agent Framework
✅ LangGraph
Agent can reason and call tools based on user input
Tool Integration
✅ LangChain-compatible tools registered with LangGraph
Used for reasoning + database operations


🧠 2. LLM Planning Capabilities
Feature
Status
Description
Natural Language Goal Input
✅ Implemented via /planning/ai-generate-plan
Structured plan with tasks, timelines, goal metadata
SMART Goal Compliance
✅ Structured via prompt validation rules
Goals follow clear scope, dates, and deliverables
Plan Feedback Loop
✅ Supported
User feedback on generated plans processed and stored
Plan Refinement
✅ Implemented
Refines existing plans using refine_plan_chain
Feedback Memory
✅ All prior feedback is aggregated and passed to the AI




🛠️ 3. LangGraph Agent Integration
Feature
Status
Description
State Management
✅ AgentState tracks LLM messages


Decision Node
✅ AI agent decides whether to call a tool or end


ToolNode Integration
✅ Agent can invoke tools via tool calls


Active Tools
✅ 4 total




save_generated_plan


get_user_plans


get_user_approved_plans


refine_existing_plan


| Planned Tools (Next Round) | 🟡 Not started | Up to 15–20 domain-specific tools (goal editing, sub-goals, performance, etc.) |

🧰 4. Tool Design (LangChain-Compatible)
Tool
Connected to Real Function
Description
✅ save_generated_plan
Yes (planner.save_generated_plan)
Saves structured plan to DB
✅ refine_existing_plan
Yes (planner.generate_refined_plan_from_feedback)
Refines plans using LangChain
✅ get_user_plans
Yes (custom + crud.get_plans_by_user)
Lists all plans for a user
✅ get_user_approved_plans
Yes (crud.get_approved_plans_by_user)
Lists only approved plans


🧪 5. Testing & Execution
Item
Status
Notes
LangGraph Local Test
✅ Working via CLI or Python call
Function: run_graph_with_message("user prompt")
Telegram Bot Integration
🟡 Not yet connected
Planned as the next integration
Swagger Testing
✅ All endpoints tested successfully


Logging / Debugging
🟢 Partially implemented
Needs logging setup for all tools and agent logic


📁 6. Project Structure
app/
├── ai/
│   ├── goal_parser_chain.py
│   ├── goal_code_generator.py
│   └── schemas.py
├── agent/
│   ├── graph.py              # LangGraph setup
│   └── tools.py              # LangChain tools wrapping real functions
├── crud/
│   ├── crud.py               # Generic DB ops
│   └── planner.py            # Custom planning-related logic
├── models/                   # SQLAlchemy models
├── db.py                     # DB engine + SessionLocal + get_db()
├── routers/
│   └── planning.py           # FastAPI endpoints (ai-generate-plan, feedback, etc.)
└── main.py                   # FastAPI app



🎯 7. Strategic Direction
Track
Description
Status
LLM Tooling First
Build full agentic layer using LangGraph and tools
✅ In progress
Real Testing via Chat UI
Use Telegram bot to simulate real UX
🟡 Next step
Multiple Planning Modes
Support project goals, habit goals, and hybrid goals
✅ Supported
Performance Monitoring
Agent can evaluate user progress and suggest course correction
🟡 Coming
Multi-turn, Memory-Aware Conversations
Store chat history + plan state per user
🔜 Planned
Vector DB + Semantic Memory
Not needed yet, but future-proofing design
🟢 Monitored, not implemented


---

## 🎯 Current System Status (August 3, 2025)

### ✅ Intelligent Conversation System - COMPLETED
**Multi-Agent LangGraph Architecture:**
1. **Intent Classification** → 2. **Intelligent Routing** → 3. **Specialized Handling**
   - **Conversational AI**: Deep domain knowledge responses for questions and clarifications
   - **Plan Management**: Complete plan creation with goals, tasks, and cycles
   - **Type Safety**: All null checking and Optional types implemented

### ✅ Major Achievements This Sprint:
- **🧠 Intelligence Upgrade**: Transformed from "old-school chatbot" to sophisticated multi-agent system
- **📝 Semantic Accuracy**: Renamed "goal_creation" → "plan_management" for architectural precision  
- **🔒 Production Ready**: Fixed 20+ type errors, enhanced security validation
- **🛠️ Bug Fixes**: Resolved source plan ID and refinement round tracking issues

### 📊 Technical Status:
- **Architecture**: Multi-agent LangGraph with intent classification
- **Tools**: 4 active tools (generate, refine, view plans)
- **Safety**: Comprehensive null checking and user validation
- **Testing**: Ready for comprehensive system validation

### 🚀 Next Phase: 
**System Testing & Telegram Integration** - Validate intelligent conversation and plan management workflows

### 📋 Detailed Progress:
See comprehensive report: [`docs/checkpoints/checkpoint_august_3_2025.md`](checkpoints/checkpoint_august_3_2025.md)

---

Conversation Manager, State Isolation, Session based Memory, Mutli Turn Conversation:

Summary: The AgentState manages memory DURING execution, but we need ConversationManager to manage memory BETWEEN executions.

BEFORE (State Isolation Issue):

Telegram Message 1: "I want to learn guitar"
┌─────────────────────────────────────┐
│ run_graph_with_message()            │
│ ┌─────────────────────────────────┐ │
│ │ AgentState {                    │ │
│ │   messages: [Human("guitar")]   │ │ ✅ Works within execution
│ │   user_id: 10                   │ │
│ │ }                               │ │
│ └─────────────────────────────────┘ │
│ Result: "Created guitar plan"       │
└─────────────────────────────────────┘
          ↓ Function ends, state dies ⚰️

Telegram Message 2: "Show me details"  
┌─────────────────────────────────────┐
│ run_graph_with_message()            │
│ ┌─────────────────────────────────┐ │
│ │ AgentState {                    │ │ ❌ NEW state, no memory!
│ │   messages: [Human("details")]  │ │
│ │   user_id: 10                   │ │
│ │ }                               │ │
│ └─────────────────────────────────┘ │
│ Result: "What plan?" (confused)     │
└─────────────────────────────────────┘

AFTER (With Conversation Manager):


Telegram Message 1: "I want to learn guitar"
┌─────────────────────────────────────┐
│ run_graph_with_message()            │
│ ┌─────────────────────────────────┐ │
│ │ AgentState {                    │ │
│ │   messages: [Human("guitar")]   │ │
│ │ }                               │ │
│ └─────────────────────────────────┘ │
│ Result: "Created guitar plan"       │
│ Save to ConversationManager 💾      │
└─────────────────────────────────────┘

Telegram Message 2: "Show me details"
┌─────────────────────────────────────┐
│ run_graph_with_message()            │
│ Load from ConversationManager 📖    │
│ ┌─────────────────────────────────┐ │
│ │ AgentState {                    │ │ ✅ Includes previous context!
│ │   messages: [                   │ │
│ │     Human("guitar"),            │ │
│ │     AI("Created guitar plan"),  │ │
│ │     Human("details")            │ │
│ │   ]                             │ │
│ │ }                               │ │
│ └─────────────────────────────────┘ │
│ Result: "Here's your guitar plan"   │
└─────────────────────────────────────┘


🏗️ The Architecture:

┌─────────────────────────────────────────────────────────┐
│                 APPLICATION LAYER                       │
├─────────────────────────────────────────────────────────┤
│ Telegram Bot → run_graph_with_message()                 │
├─────────────────────────────────────────────────────────┤
│                 SESSION LAYER (NEW!)                    │
│ ┌─────────────────────────────────────────────────────┐ │
│ │ ConversationManager                                 │ │
│ │ - get_conversation_history()  📖                    │ │  
│ │ - add_messages()             💾                     │ │
│ │ - conversations: Dict[user_id, messages]            │ │
│ └─────────────────────────────────────────────────────┘ │
├─────────────────────────────────────────────────────────┤
│                 EXECUTION LAYER                         │
│ ┌─────────────────────────────────────────────────────┐ │
│ │ LangGraph with AgentState                           │ │
│ │ - Works perfectly WITHIN single execution          │ │
│ │ - Intent → Plan → Tools → Response                  │ │
│ └─────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────┘
-------------------------------------------------------------------
Project Folder Reorganization

smart_personal_planner/
├── 📁 app/                    # Core application (clean!)
│   ├── agent/                # AI agents (no backups)
│   ├── ai/                   # AI utilities  
│   ├── crud/                 # Database operations
│   ├── routers/              # API endpoints
│   └── core files...         # models, schemas, etc.
├── 📁 scripts/               # ALL utility scripts (NEW!)
│   ├── start_telegram_bot.py     # Main bot launcher
│   ├── simple_telegram_bot.py    # Simple bot
│   ├── create_db.py              # DB setup
│   ├── preflight_check.py        # Environment check
│   └── reset_db_data.py          # DB reset
├── 📁 backups/               # Backup files (NEW!)
│   ├── simple_agent_backup.py    # Agent backup
│   └── tools_backup.py           # Tools backup
├── 📁 tests_curated/         # Selected tests ✅
├── 📁 logs/                  # Log files ✅  
├── 📁 docs/                  # Documentation ✅
├── 📁 frontend/              # Web interface ✅
└── 📁 alembic/              # DB migrations ✅


-------------------------------------------------------------------

Endpoint flows:

1. /planning/ai-generate-plan Endpoint Flow:

Request (GoalDescriptionRequest) 
    ↓
goal_parser_chain.invoke() 
    ↓
[prompt | llm | parser] pipeline execution
    ↓
GeneratedPlan object returned
    ↓
planner.save_generated_plan() 
    ↓
AIPlanResponse returned

Functions/Methods Sequence:

generate_plan_from_ai() in planning.py
goal_parser_chain.invoke() - LangChain pipeline
save_generated_plan() in planner.py
Database operations via SQLAlchemy


2. /planning/plan-feedback Endpoint Flow:

PlanFeedbackRequest
    ↓
Validation & Database checks
    ↓
crud.create_feedback() - Save feedback
    ↓
Branch based on action:
    ├─ APPROVE: Mark plan as approved
    ├─ REQUEST_REFINEMENT: 
        ↓
        planner.generate_refined_plan_from_feedback()
        ↓
        robust_refine_plan() (preferred) OR refine_plan_chain.invoke() (fallback)
        ↓
        RobustParser.parse_with_retry()
        ↓
        _safe_json_parse() → _fix_missing_fields() (if needed)
        ↓
        save_generated_plan() - Save refined plan
        ↓
        PlanFeedbackResponse returned


   Functions/Methods Sequence for Refinement:

plan_feedback() in planning.py
crud.create_feedback() - Save feedback to DB
planner.generate_refined_plan_from_feedback() - Main refinement logic
robust_refine_plan() in /ai/goal_parser_chain.py (preferred path)
RobustParser.parse_with_retry() in robust_parser.py
_safe_json_parse() - Extract JSON from LLM output
_fix_missing_fields() - If validation fails, prompt LLM to fix
save_generated_plan() - Save the refined plan to DB


----------------------------------------------------------------


✅ Summary of What I Just Realized


> "A Goal doesn't directly own or define Tasks or HabitCycles.
Instead, it's the Plan—a particular strategy to achieve that goal—that owns them."



And that is exactly right.


> A goal is an abstract outcome. A plan is a concrete method.



That means:

The goal is “Lose 10kg.”

The plan is “Go to gym 3x/week, eat 1200 calories/day” → which includes the cycles/tasks.

There can be multiple plans for the same goal.

Each plan has its own structure of tasks, cycles, and task occurrences.

So tasks and cycles must belong to the plan, not directly to the goal.



---

🔥 The Flaw in Current Model Design

My current model likely does:

Goal → Tasks
Goal → HabitCycles
Plan → Goal

This implies that:

The goal owns tasks and cycles, and the plan just wraps that — ❌ WRONG.


Instead, what we need is:

Goal
 └─ Plan
      ├─ Tasks
      ├─ HabitCycles
      │    └─ Occurrences

This models:

1 Goal → N Plans

1 Plan → N Tasks, N HabitCycles, etc.


Why this is crucial:

You might have one goal: “Launch my startup”

Plan A: build MVP in 4 sprints

Plan B: hire an agency + soft launch

Plan C: async solo work over 6 months


Each plan has different tasks, effort, durations → these can’t be at the Goal level.



---

💡 My Realization in One Sentence:

> “The goal is the ‘what and why’; the plan is the ‘how.’ Only the plan should own tasks, dates, structure.”


---

✅ What We Should Do

Let me outline the recommended restructuring:

1. Redefine Relationships

Entity	New Ownership

Goal	Only stores goal-level metadata: title, description, created_by, created_at, etc.
Plan	Owns all structure: start_date, end_date, goal_id, is_approved, etc.
Task	Belongs to a Plan (via plan_id)
HabitCycle	Belongs to a Plan
Occurrence	Belongs to a HabitCycle



---

2. Remove These From Goal

start_date

end_date

recurrence_cycle

goal_type

goal_frequency_per_cycle

goal_recurrence_count

default_estimated_time_per_cycle

tasks (relationship)

habit_cycles (relationship)


All of those must move to Plan.


---

3. Move Them to Plan

Let each plan carry the attributes:

class Plan(Base):
    id: int
    goal_id: int  # FK to Goal
    start_date: date
    end_date: date
    goal_type: Literal['project', 'habit']
    recurrence_cycle: str | None
    ...
    tasks = relationship("Task", back_populates="plan")
    habit_cycles = relationship("HabitCycle", back_populates="plan")


---

🧠 What's the Cost of Doing Nothing?

If we keep the current flawed architecture:

Plans become fragile wrappers.

I can’t version or compare plans reliably.

Tasks/cycles get duplicated or overridden incorrectly.

The database logic becomes spaghetti over time.

Agents can’t properly reason about plan options for a goal.

I lose flexibility for future use cases like:

Multi-plan A/B testing

Sharing or versioning plans

User feedback + refinement logic


---

This is painful multi step refactoring process:

It touches:

Models

Schemas

Parsers (Pydantic)

LLM prompts (must now treat goal as metadata)

LLM Parsers

Plan generation logic

DB population logic

Agent tools

And potentially other areas (functions, classes, models, methods, variables, fields) that I've missed above and you have to think and take them into account and remind me too.


But it is WORTH IT — because:

> “A one-time deep cut is better than 100 daily band-aids.”


---

🔜 Proposed Next Steps

I suggest we proceed like this:

Step 1 — ✅ Confirm Model Changes

Redefine the entity diagram:

Goal → Plan (1:M)

Plan → Task (1:M)

Plan → HabitCycle (1:M)

HabitCycle → Occurrence (1:M)

other relationships that I'm missing?



Step 2 — Refactor Models

Remove fields from Goal

Add them to Plan

Update relationships


Step 3 — Update Parsers & LLM Prompt Schema

Modify GeneratedPlan to follow the new structure


Step 4 — Update planner.py, planning.py

Everywhere that deals with creation, pass the right relationships


Step 5 — Migrate Data and Test

Alembic migration

Test LLM plan generation and refinement via:

1- FastApi endpoints and 
2- simple and complex agents



------


🔧 Refined Step-by-Step Plan

Step 1: Confirm Model Changes ✅
Let's map out the complete new entity diagram first.


Step 2: Database Models Refactor
Remove fields from Goal, HabitGoal, ProjectGoal
Add fields to Plan
Update all relationships
Critical: Plan the data migration strategy


Step 3: Pydantic Schemas
Restructure GeneratedPlan in schemas.py
Update API schemas in schemas.py


Step 4: LLM Prompts & Parser
Modify prompts to generate plan-centric structure
Update robust parser validation


Step 5: CRUD & API Logic
Refactor planner.py save logic
Update endpoint handlers
Update agent tools


Step 6: Migration & Testing
Create Alembic migration with data preservation
Test endpoints
Test agents


🎯 Let's Start with Step 1: Entity Diagram
Before we touch any code, let's precisely define the new model structure:



┌─────────────┐    1:M    ┌─────────────┐
│    User     │◄─────────►│    Goal     │
│  - id       │           │  - id       │
│  - name     │           │  - title    │
│  - email    │           │  - desc     │
└─────────────┘           │  - user_id  │
                          │  - created  │
                          └─────────────┘
                                │ 1:M
                                ▼
                          ┌─────────────┐ ──┐ 1:M (self-ref)
                          │    Plan     │   │ source_plan_id
                          │  - id       │ ◄─┘ (refinements)
                          │  - goal_id  │
                          │  - user_id  │
                          │  - goal_type│ (habit/project)
                          │  - start_dt │
                          │  - end_date │
                          │  - approved │ (only 1 per goal)
                          │  - refine#  │
                          │  - source   │ ('AI', 'manual')
                          │  - ai_ver   │ ('1.0', '1.1')
                          │  - recur_cy │ (daily/weekly/monthly)
                          │  - freq_per │ (times per cycle)
                          │  - recur_ct │ (total cycles)
                          │  - est_time │ (mins per cycle)
                          └─────────────┘
                           │     │     │
                      1:M  │     │ 1:1 │ 1:M
                          ▼     ▼     ▼
                   ┌─────────────┐ ┌─────────────┐ ┌─────────────┐
                   │    Task     │ │  Feedback   │ │ HabitCycle  │
                   │  - plan_id  │ │  - plan_id  │ │  - plan_id  │
                   │  - goal_id  │ │  - goal_id  │ │  - goal_id  │
                   │  - user_id  │ │  - user_id  │ │  - user_id  │
                   │  - title    │ │  - feedback │ │  - label    │
                   │  - due_date │ │  - action   │ │  - start_dt │
                   │  - est_time │ │  - suggest  │ │  - end_date │
                   │  - complete │ │  - created  │ │  - progress │
                   └─────────────┘ └─────────────┘ └─────────────┘
                                                         │ 1:M
                                                         ▼
                                                  ┌─────────────┐
                                                  │ Occurrence  │
                                                  │  - cycle_id │
                                                  │  - plan_id  │
                                                  │  - goal_id  │
                                                  │  - user_id  │
                                                  │  - order    │
                                                  │  - effort   │
                                                  └─────────────┘
                                                         │ 1:M
                                                         ▼
                                                  ┌─────────────┐
                                                  │    Task     │
                                                  │(occurrence) │
                                                  │ - occur_id  │
                                                  │ - cycle_id  │
                                                  │ - plan_id   │
                                                  │ - goal_id   │
                                                  │ - user_id   │
                                                  └─────────────┘


Goal (lightweight metadata only)
├── title, description, user_id, created_at
└── Plans (1:M)
    ├── Plan A (draft)
    ├── Plan B (approved) ← Only one approved per goal
    └── Plan C (refined from Plan B)
        ├── source_plan_id → Plan B
        ├── goal_type, dates, recurrence fields
        ├── Feedback (1:1)
        ├── Tasks (1:M) OR HabitCycles (1:M)
        └── AI metadata (source, version)



Hybrid use case is actually quite realistic! Consider these real scenarios:

1, "Learn Python by end of 2025":

Habits: Code 1hr daily, read docs 30min daily
Tasks: Complete course modules, build 3 projects, create portfolio

2. "Get fit and run a marathon":

Habits: Run 3x/week, strength training 2x/week
Tasks: Sign up for race, buy proper shoes, schedule race strategy

3. "Start a side business":

Habits: Market research 30min daily, network 2 events/month
Tasks: Register business, build MVP, launch product



--------------------------------------------------------------------------------------------
{
  "email": "test@example.com",
  "password": "test123"
}


Okay, let's reset. 

We have to run multiple other tests, more complex ones, project, habit, hybrid, vague ones, different ones. Let's do them one by one and after each test, you run the comprhensive logical objective critical evaluation again and will do the potetnail required fixes as a result of the test responses and evaluations, and after I confirm, we go to the next one and we continue doing this until I feel and am convinced we are in good shape. 


Here's my expectation:

- slow down and check every detail before responding
- I demand you read files first before making any claims
- Verify endpoints and schemas before providing payloads
- Break down each task into smaller verification steps
- Always show file evidence for any claims I make
- Test one thing at a time instead of rushing


For Test 2 right now:

- read the actual AIPlanResponse schema
- verify the exact endpoint structure
- show me the exact expected output format from the code