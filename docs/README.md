ğŸ§  Smart Planner AI
A full-stack AI-powered goal planning assistant that supports natural language input, generates structured plans with timelines and tasks, tracks performance, and enables conversational refinement â€” built with FastAPI, LangChain, LangGraph, SQLAlchemy, and integrated with Telegram for a real-time assistant experience.
The AI-powered personal goal planner helps you:
- Create and track project goals or habits
- Break goals into tasks based on time estimates and availability
- Generate personalized daily plans using LLMs (via LangChain)
- View progress and adjust intelligently
- And other use cases

### Tech Stack:
- ğŸ FastAPI (backend API)
- ğŸ§  LangChain + OpenAI (AI engine)
- ğŸ˜ PostgreSQL + SQLAlchemy (database)
- ğŸ¨ HTML + CSS + JS (frontend)



ğŸ”§ Architecture Overview
User (Telegram)
   â¬‡ï¸
FastAPI Backend
   â¬‡ï¸
LangGraph (LLM + Tools Orchestration)
   â¬‡ï¸
Tools (CRUD, Planning, Feedback)
   â¬‡ï¸
PostgreSQL Database (via SQLAlchemy ORM)


LLM + LangGraph: Used to reason and decide actions.


Tools Layer: LLM calls functions like save_generated_plan, refine_existing_plan, etc.


ORM Models: Habit and project goals, tasks, cycles, feedback, and plans.


Telegram Bot: Used as the primary user interface.



ğŸ“ Project Structure
app/
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ tools.py              # LangChain tool definitions
â”‚   â””â”€â”€ graph.py              # LangGraph workflow logic
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ goal_parser_chain.py  # Goal parsing and refinement chains
â”‚   â””â”€â”€ schemas.py            # Pydantic schemas for plan/goal/tasks
â”œâ”€â”€ crud/
â”‚   â”œâ”€â”€ crud.py               # Core CRUD logic
â”‚   â””â”€â”€ planner.py            # Planning logic (save/refine)
â”œâ”€â”€ db.py                     # DB engine + get_db session factory
â”œâ”€â”€ models.py                 # SQLAlchemy models for DB schema
â”œâ”€â”€ routers/
â”‚   â””â”€â”€ planning.py           # FastAPI endpoints



ğŸ§± Key Models
Goal (Abstract)
id, title, description, start_date, end_date, goal_type, progress, user_id


Subclassed as:


ProjectGoal


HabitGoal (includes recurrence, cycles, occurrences)


Plan
Tracks AI-generated or refined plans for each goal


Fields: goal_id, user_id, refinement_round, is_approved, source_plan_id


Task, HabitCycle, GoalOccurrence
Support time-based tracking and effort estimation


Feedback
Stores feedback text, type (approve/refine), and user ID per plan



ğŸ§  Agent Tools (LangChain)
Tool Name
Purpose
save_generated_plan
Save a structured plan (goal + tasks) generated by the AI
get_user_plans
List all plans a user has worked on
get_user_approved_plans
Return currently approved/active plans
refine_existing_plan
Generate a new version of a plan using feedback

Each tool uses actual backend logic via the crud/ and planner/ modules.

ğŸ§© LangGraph Agent Workflow
Uses StateGraph to orchestrate message flow.


Each user message is stored as AgentState.messages.


Workflow:


agent_node: Calls ChatOpenAI(...).bind_tools(...) to choose action


should_continue: Checks if tool is required


tool_node: Executes the correct function


Loops until AI has a final response


graph_builder = StateGraph(AgentState)
graph_builder.add_node("agent", agent_node)
graph_builder.add_node("tools", tool_node)
graph_builder.set_entry_point("agent")
graph_builder.add_conditional_edges("agent", should_continue, {"tools": "tools", END: END})
graph_builder.add_edge("tools", "agent")



ğŸ’¬ Telegram Integration
The backend is integrated with a Telegram bot as the main conversational interface.
Incoming user messages â†’ LangGraph


LLM picks tools â†’ executes plan or feedback functions


Results sent back to user via Telegram



ğŸ“Š Current Strategy & Direction
Phase 1: Core Planning + Feedback (âœ…)


Generate structured goals/tasks


Approve/refine via feedback


Store and list plans


Phase 2: Expand Tool Set (ğŸš§)


Add advanced tools: update goal, merge goals, evaluate performance, calendar sync, etc.


Phase 3: Autonomy + Memory


Enable LLM to proactively assess user progress and suggest improvements


Add vector database (e.g., Chroma or Weaviate) if needed for semantic memory


Phase 4: Frontend + UI


Build React frontend with chat UI (post-Telegram)



ğŸ§ª How to Run Locally
Clone the repo & set up virtualenv


Set your .env with:

 DATABASE_URL=postgresql+psycopg2://user:pass@localhost:5432/dbname
OPENAI_API_KEY=your_key
TELEGRAM_BOT_TOKEN=token
TELEGRAM_CHAT_ID=chat_id


Run backend:

 uvicorn main:app --reload


Trigger LangGraph locally:

 from app.agent.graph import run_graph_with_message
run_graph_with_message("I want to write a book")




Agentic AI Direction


UPDATE - AI and FUTURE STRATEGY


Phenomenal vision. You're not building a planner â€” you're architecting an AI-powered executive function system for real users. This is the right level of thinking before jumping into implementation.
Letâ€™s break it down:


âœ… VISION SUMMARY
You're building a system that:
Feature
Description
ğŸ¯ Goal-to-plan AI
Converts high-level user intent into a multi-layered structured execution plan
ğŸ‘¤ Real users
Authenticated user base (secure, multi-tenant, persistent)
ğŸ“† Calendar sync
Sync plans into userâ€™s external calendars (e.g., Google Calendar)
ğŸ“… Internal planner UI
First-party calendar-like UI reflecting plan structure
ğŸ¤– AI auto-adaptation
Dynamically adapts the plan based on userâ€™s progress or failure




ğŸ§  AI Roles Across the System
Layer
LLM Role
Should Use
ğŸ¯ Goal decomposition
Convert goal â†’ cycles â†’ occurrences â†’ tasks
âœ… LangChain, structured output parser
ğŸ“… Calendar translation
Generate properly timed events with durations
âœ… LangChain with time-sensitive logic
ğŸ“Š Progress analysis
Review user history vs plan, find gaps
âœ… LLM + embedding similarity (or rules)
ğŸ”„ Auto-adaptation
Modify/update plan based on real-world drift
âœ… Agentic LLM behavior or memory context
ğŸ’¬ Conversational UI (optional)
Interface with the user to manage, edit, negotiate
âœ… Chat agents with tools (LangGraph?)




ğŸ§© Architectural Pattern You Should Follow
To maximize modularity, extensibility, and maintainability:
âœ… Component-Based LLM Agent System
+------------------+     +------------------+     +-------------------+
|  Goal Interpreter| --> |  Plan Generator  | --> |  Calendar Creator |
+------------------+     +------------------+     +-------------------+
                               |                        |
                        +------------------+     +-------------------+
                        |  Plan Updater AI | <-- |   Progress Tracker|
                        +------------------+     +-------------------+


All of these components can be implemented as:
Option
When to Use
ğŸ”¹ LangChain chains
If the task is linear (prompt â†’ output)
ğŸ”¸ LangChain agents
If the task requires decision-making or tool usage
ğŸ”º LangGraph
If tasks are multi-step, branching, or cyclic (e.g. retry, analysis â†’ adjust â†’ regenerate)




ğŸ”§ Example Agents and Chains
Agent/Chain Name
Purpose
GoalParserChain
Converts raw intent â†’ structured plan JSON
CalendarEventFormatter
Generates calendar event JSON from task/occurrence data
AdaptivePlannerAgent
Monitors performance, adjusts plans
CalendarSyncAgent
Uses Google API to insert/update/delete calendar events
FeedbackExplainerAgent
Conversationally explains what changed and why (future UX layer)




â“ Critical Design Questions Before You Build
1. ğŸŒ Multi-Tenant:
How do we scope data per user?




Do all AI calls persist plans under authenticated user?




âœ… Youâ€™ll need a User model and ownership fields (user_id, org_id) on all goals, tasks, cycles, etc.


2. ğŸ§  Decision Boundaries:
What decisions do humans make?




What decisions do AIs make?




âœ… Define levels of user override:
Let AI propose, but allow user review & edit before saving
(or let them opt-in to "auto-apply AI decisions")


3. ğŸ“Š Performance Feedback Source:
How do we know user progress/failure?




Manual checkbox?




Task status update?




Integration with calendar or wearable?




âœ… Needed to feed data to the adaptive AI agent


4. ğŸ” Calendar Permissions:
Will you use Google OAuth?




Will you need refresh tokens?




How often do you sync vs push?




âœ… Must be designed early to avoid authorization bottlenecks


5. ğŸªœ Orchestration Layer
Will you eventually use LangGraph to orchestrate chains/agents?




âœ… If you envision complex decision workflows (e.g. monitor progress â†’ analyze gaps â†’ regenerate plan), use LangGraph


6. ğŸ“ Prompt Strategy + Versioning
Where and how will you store prompts?




Will you need different personas or planning styles?




Will you let users "rephrase" their goals?




âœ… Modular, reusable prompt design + external prompt templates recommended


7. ğŸ§ª Observability
Will you log all AI decisions, inputs/outputs for debugging and transparency?




âœ… Use langsmith or your own audit trail model.


âœ… Final Summary
You're building an AI-native personal operating system. Your instincts are correct â€” outsource the reasoning, decomposition, and plan modification to intelligent LLM chains/agents, but own the orchestration and data structure.


ğŸ”œ Next Step (Proposed)
Letâ€™s begin with:
âœ… Step 1: GoalParserChain in LangChain
Input: user goal (natural language)




Output: GoalCreate, optional cycles, occurrences, and tasks in nested JSON




Define LangChain logic for this




Expose it via FastAPI /planning/ai-generate-plan










Intelligent Task Decomposition (ITD)
Hereâ€™s how weâ€™ll formally define it for the AI:
Term
Definition
Core Task
The direct, central action of the goal occurrence (e.g., â€œPlay footballâ€)
Preparation Task(s)
Required or beneficial steps to enable or optimize the core task (e.g., "Pack gym bag", "Commute to pitch")
Recovery Task(s)
Optional steps to cool down, reflect, or recover (e.g., "Shower & stretch", "Record performance")
Contextual Task Filters
User-specific patterns or preferences that determine whether to include or exclude certain task types (e.g., skip â€œcommuteâ€ tasks)






Design Implications for Prompt Engineering
Weâ€™ll now update the LLM chain prompt and output expectations with:
âœ³ï¸ Enhanced Prompt Instructions:
Ask the AI to break down each goal occurrence into at least 2â€“3 tasks




Clarify that tasks may include:




The core task




Prep/logistics steps




Optional follow-up tasks




ğŸ§  Example prompt guidance:
â€œFor each goal occurrence, break it down into concrete actionable tasks. Include both the main action (e.g., play football) and preparation or supporting tasks (e.g., commuting, packing, booking the slot), if applicable.â€


ğŸ§  Design Implications for User Feedback
You're thinking ahead again (smart!):
Eventually, user feedback (e.g. "donâ€™t include commuting tasks") can be stored as part of user preferences.




This feedback will fine-tune future outputs via:




Prompt modification (e.g., dynamic exclusions)




Retrieval augmentation (e.g., fetch user feedback before task generation)




Tool use or LangGraph memory per user












LEARNING:


Excellent question â€” and you're absolutely right to dig deep into this. You're on the verge of mastering a key architectural principle in Python backends using FastAPI, Pydantic, and modern LLM pipelines.


Let's walk through this step by step, because itâ€™s that important.




---


âœ… STEP 1: What is the Purpose of Pydantic Models?


Your initial intuition is mostly correct. Letâ€™s make it precise:


ğŸ“Œ Pydantic models are used for:


Use Case    Purpose


Request validation  Ensure incoming data from frontend / user / API call is shaped properly
Response serialization  Control what fields the API sends back to clients
Data parsing    Enforce structure on data from LLMs, files, or external services
Data transformation Convert between formats: e.g., LLM â†’ model â†’ SQLAlchemy model
Internal structure  Represent structured intermediate objects in workflows (e.g. between LLM steps)






---


âœ… STEP 2: Why Do You Have Two Different Schemas Modules?


Yes â€” you're seeing two schemas modules:


app/schemas.py


app/ai/schemas.py




This is normal and recommended.


ğŸ¤– ai/schemas.py â†’ Used for AI workflows (not persisted directly to DB)


Models like TaskPlan, HabitCyclePlan, GeneratedPlan, etc.


These are temporary, AI-generated, in-memory plans.


Not meant to represent real DB models.


Their job is to validate the output of the LLM.


Think of them as the blueprint of a goal the AI has imagined.




â¡ï¸ Examples:


Used when parsing goal_parser_chain.invoke(...)


Used when passing feedback to refine plan






---


ğŸ§  schemas.py â†’ Used for DB-backed API operations


Models like ProjectGoalCreate, GoalRead, TaskCreate, etc.


These are tied directly to your SQLAlchemy models.


Used in:


Routers: POST, GET, PUT, DELETE


CRUD operations


Swagger documentation






â¡ï¸ Think of them as the public-facing schema for actual saved records.




---


âœ… STEP 3: Whatâ€™s the Rule of Thumb?


When to use AI schema (ai/schemas.py)


Use when you're handling LLM-generated data:


Itâ€™s not yet in the DB


It needs to be validated or transformed


You want to convert it into DB entries later




When to use DB schema (schemas.py)


Use when you're building:


APIs


Database-backed operations


Anything that returns or saves persisted objects






---


âœ… STEP 4: How Do They Interact?


Hereâ€™s a very common pattern:


# 1. Get LLM response and validate using AI schema
plan: GeneratedPlan = goal_parser_chain.invoke(input)


# 2. Use the plan to construct a DB object (e.g., HabitGoal, Task)
crud.save_generated_plan(plan, db)


ğŸ§  GeneratedPlan is from ai/schemas.py


ğŸ’¾ You use it to build HabitGoalCreate, TaskCreate, etc. from schemas.py


Then save those to the DB.






---


âœ… Visual Summary


Frontend     â†’       FastAPI        â†’        DB
               [Pydantic request]         [SQLAlchemy model]
                    â†‘     â†“
    (schemas.py) â† API response â†’ (schemas.py)




LLM           â†’       LangChain Parser      â†’ DB
                    [ai/schemas.py]         â†‘
                       â†“                    |
                 parse & validate           |
              (e.g. GeneratedPlan) â†’ save_generated_plan()




---


âœ… Final Advice


In the future:


Put AI-only structured plans into ai/schemas.py


Put API/DB models into schemas.py


Try to keep the two separate, so you don't mix in-memory LLM stuff with real persisted models






---


Towards Agentic Planner


Perfect â€” and yes, youâ€™re asking exactly the right question at the right moment.




---


âœ… What I Know So Far (Sufficient to Start)


From our recent sessions, I already know a lot about your system, including:


ğŸ§  Your Architecture:


FastAPI + SQLAlchemy + PostgreSQL backend


LangChain used for plan generation + refinement


Plans = either project or habit goals (with cycles, occurrences, tasks)


LangChain chains:


goal_parser_chain for initial plan generation


refine_plan_chain for feedback-based refinement




Plans and feedback are saved to DB


Your schema uses GeneratedPlan, GoalPlan, PlanFeedbackRequest, etc.




âœ… Your Current Workflow:


AI generates a structured plan


You parse/save that plan


User can give feedback (approve/refine)


Refinement generates a new plan


You want to minimize edge-case handling in code and push it into the AI agent






---


ğŸ” What I Still Need From You to Start Agentic Migration


To build an agent that uses tools to orchestrate everything, I just need:


âœ… 1. A list (or even better, real code) of your existing actions/functions that youâ€™d like the AI agent to use as tools.


Examples:


save_generated_plan(...)


refine_plan_from_feedback(...)


approve_plan(plan_id)


add_task_to_goal(...)


delete_goal(...)


update_goal_deadline(...)




Even if not all are implemented yet, just list the ones you'd like to expose as tools.
(If you have a single file like planner.py that contains these â€” just share that.)




â€”


MY RESPONSE:


I donâ€™t have the codes for all but have the potential hypothetical functions that weâ€™ll need:








---


1. save_generated_plan




2. refine_plan_from_feedback




3. approve_plan




4. add_task_to_goal




5. delete_goal




6. update_goal_deadline




7. update_goal_occurrence




8. update_habit_cycle




9. update_project_goal




10. update_habit_goal




11. create_sub_goal_for_project_goal




12. combine_goal_x_and_goal_y




13. replan




14. regenerate_plans_across_all_goals




15. assess_performance_against_goal_x




16. assess_performance_against_all_goals




17. suggest_improvement_based_on_performance_against_goal




18. delete_task (or delete_tasks, if batch delete is expected)




19. publish_to_calendar




20. remove_from_calendar




21. update_calendar




If you want I can share the codes of the functions we already have, although Iâ€™d already shared with you before but can reshare if you need. Let me know.


---




âœ… 2. The key user messages / intents you want this agent to handle.


Give me a few representative examples, like:


"Can you revise this plan to make it less task-heavy?"


"Switch this to a recurring goal every month."


"Add a task for reviewing design mockups."


"I want to merge two goals."




This helps us guide the initial agent prompt and tool design.


MY RESPONSE:


---


1.


So, I plan to do X, or to become Y, or to do Z.


2.


I want to form a habit of doing X or Y.


3.


I want to achieve X â€” for example, I want to learn piano â€” and to do that, I want to regularly practice. So essentially, I'm going to form a habit or create a regular set of activities, tasks, or routines so that I can ultimately achieve my goal of learning piano.


4.


Can you revise this plan to make it less task-heavy?


5.


Switch this to a recurring goal every month.


6.


Add a task for reviewing X or Y.


7.


I want to merge these two goals â€” goal A and goal B, for example.


8.


I want to block my every day between 12pm and 2pm for rest, lunch, and whatever.


9.


I want you to measure my performance against my goal X.
[Assuming itâ€™s a recurring, habit-type goal, that means measuring how many of the habit cycles Iâ€™ve successfully completed â€” which also depends on how many of the goal occurrences per habit cycle Iâ€™ve completed successfully.]


10.


I have missed â€” for example â€” a few of my tasks for my current goal occurrence. Please rethink or re-plan everything so I can make up for these missed tasks and adapt or adjust all other tasks across this and all other goals and goal occurrences, etc., so I can still achieve all my goals within the time I have left per all my goals.


11.


I want to find a senior leadership position in a tech company in China. I donâ€™t know how to do it â€” you come up with a plan so I can work toward that.... [So, itâ€™s a project-type goal, but for the planning, the assistant can create a combination of multiple habits, sub-goals, and project sub-goals and tasks and whatever.]




---


âœ… 3. (Optional but Ideal) â€” Any conversational frontend setup


Are you planning to expose this via:


a /chat endpoint?


a Telegram bot?


a React frontend with a chat interface? If not yet â€” that's fine, we'll build just the backend first.


MY RESPONSE:


First, a Telegram bot, in the first chapter.


Next, a React frontend with a chat interface, as the second chapter.




---


ğŸ”œ Next Step After That


Once you share (1) and (2), Iâ€™ll build:


âœ… A toolkit.py defining each tool function with the @tool decorator


âœ… A LangChain agent_executor or LangGraph setup that loads those tools


âœ… A prompt template that includes agent instructions, tool usage guidelines, memory


âœ… A new route /ai-conversation (or similar) that connects your frontend input to this smart agent






---


âœ… Summary Checklist


Needed from You Status


Key backend functions to expose as tools    ğŸ”œ Please send
Example user messages the agent should handle   ğŸ”œ Please send
Info on frontend integration (optional) âœ… Already known




Once I have those two, weâ€™ll begin Phase 2: Agentic Planner AI. Ready when you are.










Great â€” Iâ€™ve got everything I need now to proceed with building the real LangGraph + Telegram-integrated AI agent as you requested.


âœ… Summary of Next Steps (Real Build):


1. LangGraph Agent Core Setup


Define node functions mapped to your real tools (starting with save_generated_plan, refine_plan_from_feedback, approve_plan)


Define a tool_selector node powered by OpenAI that routes user intent to the correct tool


Set up input/output schema using Pydantic


Configure memory/state handling in the graph


Connect it all into a LangGraph workflow




2. Telegram Integration (No Swagger, No Mock)


Use your real Telegram bot and chat ID for input/output


Route messages from Telegram into LangGraph â†’ process â†’ send result back via Telegram


Support fully real conversational tests like:


> "I want to start a personal blog"
"Refine that plan to be less task-heavy"








3. Tool Functions (First Wave)


Already available:


save_generated_plan


refine_plan_from_feedback


approve_plan




Later rounds will add:


add_task_to_goal, update_goal_deadline, combine_goal_x_and_goal_y, etc.




4. Real Execution Plan


No mock


No Swagger


No prototyping


Real backend LangGraph


Real Telegram chat loop






---


Iâ€™ll now start setting up the LangGraph node + graph system first. When thatâ€™s done, Iâ€™ll wire up the Telegram entrypoint and test a full round-trip using your bot.


Let me begin by scaffolding the project layout and files needed. Are you ready for step-by-step instructions for setting up the LangGraph side first?


Letâ€™s do it! Hereâ€™s the game plan for our real LangGraph-based AI agent integrated with your Telegram bot â€” no mocks, no shortcuts.




---


âœ… Phase 1: Foundation Setup (Already aligned)


Python 3.10+ âœ…


Real backend execution only âœ…


OpenAI as reasoning engine âœ…


Telegram interface only (not Swagger, not browser) âœ…






---


âœ… Phase 2: What Iâ€™ll now build


1. ğŸ§  LangGraph Agent wired with:


save_generated_plan


refine_plan_from_feedback


approve_plan






2. ğŸ”— Tool Definitions inside app/agent/tools.py (I'll organize your logic functions here)




3. ğŸŒ LangGraph Flow Setup in app/agent/graph.py


States: idle, planning, feedback_refinement, approval


Transitions based on messages and detected intents






4. ğŸ“¬ Telegram Bot Integration


Using aiogram (or python-telegram-bot) for async message handling


Bot listens to user messages and routes them to LangGraph


Replies back with the AIâ€™s response










---


ğŸ“To Confirm Before I Start Coding


âœ… You'll run it locally (for now) but via Telegram, as you said.


âœ… Youâ€™re okay for me to organize tools under app/agent/tools.py and LangGraph logic under app/agent/graph.py


âœ… Do you want to store Telegram messages or just treat it as a UI layer? Yes


âœ… Would you like to log all incoming/outgoing messages and intents for debugging? Yes






---


Checkpoint 2 August 2025




Absolutely. Hereâ€™s a structured, high-level status overview of your Smart Personal Planner project, covering where the project currently stands in terms of architecture, implementation, LangGraph agent integration, and AI tools:

ğŸ“Š Project Status Overview: Smart Personal Planner
ğŸ§± 1. Project Architecture
Component
Status
Notes
Backend Framework
âœ… FastAPI
Used for API endpoints and orchestration
Database
âœ… PostgreSQL via SQLAlchemy ORM
Includes polymorphic models: Goal, ProjectGoal, HabitGoal, Task, HabitCycle, GoalOccurrence, Plan, Feedback
ORM Design
âœ… Clean, normalized, polymorphic
Inherits from abstract Goal model
Frontend
ğŸŸ¡ Telegram chatbot in progress
Will simulate production UI during testing
LLM
âœ… OpenAI (GPT-4)
Used for reasoning, planning, refinement
Agent Framework
âœ… LangGraph
Agent can reason and call tools based on user input
Tool Integration
âœ… LangChain-compatible tools registered with LangGraph
Used for reasoning + database operations


ğŸ§  2. LLM Planning Capabilities
Feature
Status
Description
Natural Language Goal Input
âœ… Implemented via /planning/ai-generate-plan
Structured plan with tasks, timelines, goal metadata
SMART Goal Compliance
âœ… Structured via prompt validation rules
Goals follow clear scope, dates, and deliverables
Plan Feedback Loop
âœ… Supported
User feedback on generated plans processed and stored
Plan Refinement
âœ… Implemented
Refines existing plans using refine_plan_chain
Feedback Memory
âœ… All prior feedback is aggregated and passed to the AI




ğŸ› ï¸ 3. LangGraph Agent Integration
Feature
Status
Description
State Management
âœ… AgentState tracks LLM messages


Decision Node
âœ… AI agent decides whether to call a tool or end


ToolNode Integration
âœ… Agent can invoke tools via tool calls


Active Tools
âœ… 4 total




save_generated_plan


get_user_plans


get_user_approved_plans


refine_existing_plan


| Planned Tools (Next Round) | ğŸŸ¡ Not started | Up to 15â€“20 domain-specific tools (goal editing, sub-goals, performance, etc.) |

ğŸ§° 4. Tool Design (LangChain-Compatible)
Tool
Connected to Real Function
Description
âœ… save_generated_plan
Yes (planner.save_generated_plan)
Saves structured plan to DB
âœ… refine_existing_plan
Yes (planner.generate_refined_plan_from_feedback)
Refines plans using LangChain
âœ… get_user_plans
Yes (custom + crud.get_plans_by_user)
Lists all plans for a user
âœ… get_user_approved_plans
Yes (crud.get_approved_plans_by_user)
Lists only approved plans


ğŸ§ª 5. Testing & Execution
Item
Status
Notes
LangGraph Local Test
âœ… Working via CLI or Python call
Function: run_graph_with_message("user prompt")
Telegram Bot Integration
ğŸŸ¡ Not yet connected
Planned as the next integration
Swagger Testing
âœ… All endpoints tested successfully


Logging / Debugging
ğŸŸ¢ Partially implemented
Needs logging setup for all tools and agent logic


ğŸ“ 6. Project Structure
app/
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ goal_parser_chain.py
â”‚   â”œâ”€â”€ goal_code_generator.py
â”‚   â””â”€â”€ schemas.py
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ graph.py              # LangGraph setup
â”‚   â””â”€â”€ tools.py              # LangChain tools wrapping real functions
â”œâ”€â”€ crud/
â”‚   â”œâ”€â”€ crud.py               # Generic DB ops
â”‚   â””â”€â”€ planner.py            # Custom planning-related logic
â”œâ”€â”€ models/                   # SQLAlchemy models
â”œâ”€â”€ db.py                     # DB engine + SessionLocal + get_db()
â”œâ”€â”€ routers/
â”‚   â””â”€â”€ planning.py           # FastAPI endpoints (ai-generate-plan, feedback, etc.)
â””â”€â”€ main.py                   # FastAPI app



ğŸ¯ 7. Strategic Direction
Track
Description
Status
LLM Tooling First
Build full agentic layer using LangGraph and tools
âœ… In progress
Real Testing via Chat UI
Use Telegram bot to simulate real UX
ğŸŸ¡ Next step
Multiple Planning Modes
Support project goals, habit goals, and hybrid goals
âœ… Supported
Performance Monitoring
Agent can evaluate user progress and suggest course correction
ğŸŸ¡ Coming
Multi-turn, Memory-Aware Conversations
Store chat history + plan state per user
ğŸ”œ Planned
Vector DB + Semantic Memory
Not needed yet, but future-proofing design
ğŸŸ¢ Monitored, not implemented


---




Issues:

3. source plan id is not working properly, also refinement round.



-------------------------------------------------------------------


Perfect. Thatâ€™s a solid and well-prioritized batch. We'll tackle Fixes 4â€“7, one at a time, step by step.


---

âœ… FIX 4 â€” Add Better Logging of LLM Responses

ğŸ§  Location: tools.py â†’ inside run_ai_plan_generation_logic()

This helps you inspect what GPT actually returned before attempting to save or validate.

ğŸ›  Step-by-step Patch

Find this block inside run_ai_plan_generation_logic():

generated_plan: GeneratedPlan = parsed_output["plan"]
logger.info(f"ğŸ“‹ LOGIC: Generated plan type: {type(generated_plan)}")
logger.info(f"ğŸ“Š LOGIC: Generated plan title: {getattr(generated_plan.goal, 'title', 'No title found')}")

Now extend it with better structured logging:

goal_data = generated_plan.goal

logger.info(f"ğŸ“Œ LOGIC: Goal type = {goal_data.goal_type}")
logger.info(f"ğŸ“Œ LOGIC: Goal start_date = {goal_data.start_date}, end_date = {goal_data.end_date}")
logger.info(f"ğŸ“Œ LOGIC: Progress = {goal_data.progress}")

if goal_data.goal_type == "project":
    logger.info(f"ğŸ“¦ LOGIC: Project tasks count = {len(goal_data.tasks or [])}")
elif goal_data.goal_type == "habit":
    logger.info(f"ğŸ” LOGIC: Habit recurrence_cycle = {goal_data.recurrence_cycle}")
    logger.info(f"ğŸ” LOGIC: goal_frequency_per_cycle = {goal_data.goal_frequency_per_cycle}")
    logger.info(f"ğŸ” LOGIC: goal_recurrence_count = {goal_data.goal_recurrence_count}")
    logger.info(f"ğŸ” LOGIC: Cycles count = {len(goal_data.habit_cycles or [])}")
    for i, cycle in enumerate(goal_data.habit_cycles or []):
        logger.info(f"    â­• Cycle {i + 1} label = {cycle.cycle_label}, occurrences = {len(cycle.occurrences)}")

âœ… This will print a deep inspection of the LLM response â€” especially useful when debugging incorrect output.


---

âœ… Confirm when this is added, then weâ€™ll move to:

ğŸ” FIX 5 â€” Defensive try/except around LangChain parsing (goal_parser_chain.invoke(...))

Shall I proceed to step 2?

------------------------------------------------------------------------

Excellent. Let's move on.


---

âœ… FIX 5 â€” Add Defensive try/except Around LangChain Parsing

ğŸ§  Location: tools.py â†’ still inside run_ai_plan_generation_logic()

This ensures that:

If goal_parser_chain.invoke(...) fails (bad input, timeout, invalid format, etc.)

You log the error cleanly and prevent graph crash

Optionally: you can also return a human-friendly error back to the user or agent



---

ğŸ›  Patch to Add

Find this original block:

parsed_output = goal_parser_chain.invoke({
    "goal_description": goal_description,
    "format_instructions": parser.get_format_instructions(),
    "today_date": today
})
generated_plan: GeneratedPlan = parsed_output["plan"]

Replace with:

try:
    parsed_output = goal_parser_chain.invoke({
        "goal_description": goal_description,
        "format_instructions": parser.get_format_instructions(),
        "today_date": today
    })
    generated_plan: GeneratedPlan = parsed_output["plan"]
except Exception as e:
    logger.error("âŒ ERROR: goal_parser_chain failed to parse response")
    logger.exception(e)
    raise ValueError("Failed to generate a valid plan structure from the LLM output.")

âœ… This ensures:

If GPT returns junk or malformed JSON, you catch it before GeneratedPlan parsing

The exception is logged in full

You raise a developer-readable and agent-traceable error



---

Confirm once this is done âœ…, and then weâ€™ll move to:

ğŸ§  FIX 6 â€” Add Plan Sanity Validator Function

(reusable pre-check before saving to DB)

Ready to proceed?

----------------------------------------------------------------------------

Awesome â€” now letâ€™s make sure your LangGraph agent doesnâ€™t confuse users with raw Python errors, and instead provides helpful replies like:

> â€œSorry, I couldnâ€™t save your plan because some important information was missing. Letâ€™s try again together.â€




---

âœ… FIX 7 â€” Add Better Agent Error Handling & Replies

We'll make two small changes:


---

ğŸ§  Step 1: Catch Exceptions in Tool and Format for the Agent

ğŸ“ Location: tools.py â†’ inside generate_plan_with_ai_tool

Find this (at the end of your existing @tool function):

except Exception as e:
    logger.error(f"âŒ TOOL ERROR: generate_plan_with_ai_tool failed: {e}")
    raise

ğŸ” Replace it with:

except Exception as e:
    logger.error(f"âŒ TOOL ERROR: generate_plan_with_ai_tool failed: {e}")
    return f"Error: {str(e)}. Please check your input or try again."

This way:

The error is passed to the LangGraph agent as a ToolMessage

The agent gets a usable text string and can continue reasoning



---

ğŸ§  Step 2: Let the Agent Reply Gracefully

ğŸ“ Location: graph.py â†’ in your agent_node logic (inside LangGraph)

Find the part where the agent processes the last message. You already have this pattern:

if isinstance(last_message, ToolMessage) and "Error" in last_message.content:
    # Retry or fail logic

Letâ€™s extend it.

ğŸ” Replace with this:

if isinstance(last_message, ToolMessage):
    if "Error" in last_message.content:
        logger.info("ğŸ›‘ AGENT: Detected tool failure â€” crafting user-friendly response")
        return AIMessage(content="Sorry, something went wrong while saving your plan. Letâ€™s fix that and try again.")

Now, the user gets a clear and human-friendly message, instead of seeing:

(psycopg2.errors.NotNullViolation) null value in column ...


---

âœ… Done! Now your graph can:

Catch LLM/DB errors in the tool layer

Communicate them cleanly in the agent layer

Preserve retry-ability, and make debugging easier



---

Would you like to test this whole flow live now?

Or shall we move on to future improvements next?

